{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leb10\n",
    "NN, ReLu, Xavaier, Dropout, AdamOptimizer\n",
    "\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLu (x) accu=90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 5.019352907\n",
      "Epoch: 0002 Cost: 1.741589050\n",
      "Epoch: 0003 Cost: 1.153154598\n",
      "Epoch: 0004 Cost: 0.906919327\n",
      "Epoch: 0005 Cost: 0.771319092\n",
      "Epoch: 0006 Cost: 0.683326146\n",
      "Epoch: 0007 Cost: 0.621666556\n",
      "Epoch: 0008 Cost: 0.574507212\n",
      "Epoch: 0009 Cost: 0.537613306\n",
      "Epoch: 0010 Cost: 0.507432155\n",
      "Epoch: 0011 Cost: 0.483275567\n",
      "Epoch: 0012 Cost: 0.462609032\n",
      "Epoch: 0013 Cost: 0.444831168\n",
      "Epoch: 0014 Cost: 0.429085693\n",
      "Epoch: 0015 Cost: 0.415277375\n",
      "학습종료\n",
      "Accuracy :  0.8943\n",
      "Label:  [5]\n",
      "Prediction:  [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "imgSize = 28 * 28\n",
    "nb_classes = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, imgSize])\n",
    "y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "w = tf.Variable(tf.random_normal([imgSize, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# hypothesis = tf.nn.softmax(tf.matmul(layer1, w2) + b2)\n",
    "hypothesis = tf.matmul(x, w) + b\n",
    "\n",
    "#########################\n",
    "learnint_rate = 0.001\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    " \n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                  y: mnist.test.labels}))\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                   feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "          cmap='Greys',\n",
    "          interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLu (o) 95%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 157.907781171\n",
      "Epoch: 0002 Cost: 38.231654548\n",
      "Epoch: 0003 Cost: 23.828027984\n",
      "Epoch: 0004 Cost: 16.581559015\n",
      "Epoch: 0005 Cost: 12.157836584\n",
      "Epoch: 0006 Cost: 8.871932850\n",
      "Epoch: 0007 Cost: 6.660100062\n",
      "Epoch: 0008 Cost: 5.015748163\n",
      "Epoch: 0009 Cost: 3.838014692\n",
      "Epoch: 0010 Cost: 2.852372719\n",
      "Epoch: 0011 Cost: 2.197831107\n",
      "Epoch: 0012 Cost: 1.601099850\n",
      "Epoch: 0013 Cost: 1.222036244\n",
      "Epoch: 0014 Cost: 1.011425863\n",
      "Epoch: 0015 Cost: 0.743551106\n",
      "학습종료\n",
      "Accuracy :  0.9479\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "imgSize = 28 * 28\n",
    "nb_classes = 10\n",
    "rgb = 256\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, imgSize])\n",
    "y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "#########################\n",
    "w1 = tf.Variable(tf.random_normal([imgSize, rgb]))\n",
    "b1 = tf.Variable(tf.random_normal([rgb]))\n",
    "L1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([rgb, rgb]))\n",
    "b2 = tf.Variable(tf.random_normal([rgb]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, w2) + b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([rgb, nb_classes]))\n",
    "b3 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "hypothesis = tf.matmul(L2, w3) + b3\n",
    "\n",
    "#########################\n",
    "\n",
    "learnint_rate = 0.001\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    " \n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                  y: mnist.test.labels}))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLu (o) 97%\n",
    "\n",
    "### xavier initializator tensorflow\n",
    "초기 값이 잘 적용됨 cost값 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 0.312040086\n",
      "Epoch: 0002 Cost: 0.114840356\n",
      "Epoch: 0003 Cost: 0.078112489\n",
      "Epoch: 0004 Cost: 0.056915082\n",
      "Epoch: 0005 Cost: 0.041534957\n",
      "Epoch: 0006 Cost: 0.032645754\n",
      "Epoch: 0007 Cost: 0.026435628\n",
      "Epoch: 0008 Cost: 0.020738554\n",
      "Epoch: 0009 Cost: 0.017766886\n",
      "Epoch: 0010 Cost: 0.014180165\n",
      "Epoch: 0011 Cost: 0.011869437\n",
      "Epoch: 0012 Cost: 0.015519798\n",
      "Epoch: 0013 Cost: 0.009470845\n",
      "Epoch: 0014 Cost: 0.011464698\n",
      "Epoch: 0015 Cost: 0.010366568\n",
      "학습종료\n",
      "Accuracy :  0.9777\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random # random 호출 안했네\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "imgSize = 28 * 28\n",
    "nb_classes = 10\n",
    "rgb = 256\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, imgSize])\n",
    "y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "#########################\n",
    "# w1 = tf.get_variable(\"w1\", shape=[imgSize, rgb],\n",
    "#                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b1 = tf.Variable(tf.random_normal([rgb]))\n",
    "# L1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "# w2 = tf.Variable(\"w2\", shape=[rgb, rgb],\n",
    "#                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b2 = tf.Variable(tf.random_normal([rgb]))\n",
    "# L2 = tf.nn.relu(tf.matmul(L1, w2) + b2)\n",
    "\n",
    "# w3 = tf.Variable(\"w3\", shape=[rgb, nb_classes],\n",
    "#                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "# b3 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "# hypothesis = tf.matmul(L2, w3) + b3\n",
    "\n",
    "\n",
    "w1 = tf.get_variable(\"w1\", shape=[imgSize, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([rgb]))\n",
    "L1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.get_variable(\"w2\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([rgb]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, w2) + b2)\n",
    "\n",
    "w3 = tf.get_variable(\"w3\", shape=[rgb, nb_classes],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "hypothesis = tf.matmul(L2, w3) + b3\n",
    "\n",
    "#########################\n",
    "\n",
    "learnint_rate = 0.001\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    " \n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                  y: mnist.test.labels}))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLu (o) 97%\n",
    "\n",
    "### xavier initializator tensorflow\n",
    "\n",
    "### 깊게\n",
    "\n",
    "overfitting 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 0.289793072\n",
      "Epoch: 0002 Cost: 0.103626815\n",
      "Epoch: 0003 Cost: 0.070704772\n",
      "Epoch: 0004 Cost: 0.052555851\n",
      "Epoch: 0005 Cost: 0.042217172\n",
      "Epoch: 0006 Cost: 0.036034408\n",
      "Epoch: 0007 Cost: 0.029471175\n",
      "Epoch: 0008 Cost: 0.028672647\n",
      "Epoch: 0009 Cost: 0.022697113\n",
      "Epoch: 0010 Cost: 0.019959742\n",
      "Epoch: 0011 Cost: 0.019932898\n",
      "Epoch: 0012 Cost: 0.018205508\n",
      "Epoch: 0013 Cost: 0.018198262\n",
      "Epoch: 0014 Cost: 0.017937177\n",
      "Epoch: 0015 Cost: 0.013270086\n",
      "학습종료\n",
      "Accuracy :  0.976\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random # random 호출 안했네\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "##########\n",
    "\n",
    "imgSize = 28 * 28\n",
    "nb_classes = 10\n",
    "rgb = 256 * 2\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, imgSize])\n",
    "y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "#########################\n",
    "w1 = tf.get_variable(\"w1\", shape=[imgSize, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([rgb]))\n",
    "L1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.get_variable(\"w2\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([rgb]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, w2) + b2)\n",
    "\n",
    "w3 = tf.get_variable(\"w3\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([rgb]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, w3) + b3)\n",
    "\n",
    "w4 = tf.get_variable(\"w4\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([rgb]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, w4) + b4)\n",
    "\n",
    "w5 = tf.get_variable(\"w5\", shape=[rgb, nb_classes],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "\n",
    "hypothesis = tf.matmul(L4, w5) + b5\n",
    "\n",
    "#########################\n",
    "\n",
    "learnint_rate = 0.001\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    " \n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                  y: mnist.test.labels}))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting때문에 Dropout\n",
    "몇개의 노드 끊어버림\n",
    "keep_prob\n",
    "\n",
    "### 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 0.451573379\n",
      "Epoch: 0002 Cost: 0.173176348\n",
      "Epoch: 0003 Cost: 0.131343872\n",
      "Epoch: 0004 Cost: 0.110304175\n",
      "Epoch: 0005 Cost: 0.092497248\n",
      "Epoch: 0006 Cost: 0.081720577\n",
      "Epoch: 0007 Cost: 0.074482265\n",
      "Epoch: 0008 Cost: 0.068222339\n",
      "Epoch: 0009 Cost: 0.063184502\n",
      "Epoch: 0010 Cost: 0.058535071\n",
      "Epoch: 0011 Cost: 0.057575005\n",
      "Epoch: 0012 Cost: 0.053467032\n",
      "Epoch: 0013 Cost: 0.049580697\n",
      "Epoch: 0014 Cost: 0.047658107\n",
      "Epoch: 0015 Cost: 0.046830243\n",
      "학습종료\n",
      "Accuracy :  0.983\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random # random 호출 안했네\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "\n",
    "\n",
    "imgSize = 28 * 28\n",
    "nb_classes = 10\n",
    "rgb = 256 * 2\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, imgSize])\n",
    "y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "#########################\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "\n",
    "w1 = tf.get_variable(\"w1\", shape=[imgSize, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([rgb]))\n",
    "L1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "w2 = tf.get_variable(\"w2\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([rgb]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, w2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "w3 = tf.get_variable(\"w3\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([rgb]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, w3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "w4 = tf.get_variable(\"w4\", shape=[rgb, rgb],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([rgb]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, w4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "w5 = tf.get_variable(\"w5\", shape=[rgb, nb_classes],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "\n",
    "hypothesis = tf.matmul(L4, w5) + b5\n",
    "\n",
    "#########################\n",
    "# optimizer Adam, Gradient말고도 많음\n",
    "learnint_rate = 0.001\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    " \n",
    "# 학습할때는 1이아니여도\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys,\n",
    "                                      keep_prob: 0.7})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "# 실제 테스트할떄는 1이여야함\n",
    "    correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                  y: mnist.test.labels,\n",
    "                                                 keep_prob: 1}))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
