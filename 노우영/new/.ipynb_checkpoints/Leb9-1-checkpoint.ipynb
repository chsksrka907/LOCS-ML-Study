{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leb9-1\n",
    "\n",
    "## XOR 만들기\n",
    "+layer 추가, deep Mnist\n",
    "\n",
    "### float 선언하기 힘드니까 dtype=np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 한 단만 사용\n",
    "\n",
    "## Accuracy = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8698098\n",
      "0.6931577\n",
      "0.6931471\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "\n",
      "Hypothesis: \n",
      " [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x, w) + b)\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print(sess.run(cost,\n",
    "                           feed_dict={x: x_data, y: y_data}))\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 여러 단 사용\n",
    "은닉층, layer\n",
    "\n",
    "## Accuracy = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.6992402 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.6388945 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.56157905 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.5223352 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.5024475 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.46589395 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.14694032 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.06306999 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.03905259 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.028099028 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.021878116 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "\n",
      "Hypothesis: \n",
      " [[0.02088399]\n",
      " [0.968922  ]\n",
      " [0.98311883]\n",
      " [0.01765321]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "###\n",
    "w1 = tf.Variable(tf.random_normal([2, 2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([2, 1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "###\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print('cost: ',\n",
    "                  sess.run(cost, feed_dict={x: x_data, y: y_data}),\n",
    "                  '\\nweight: \\n', sess.run(w), '\\n')\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "##             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출력을 wide한 값 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.73982763 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.3917949 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.09005224 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.03951261 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.023791483 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.016611941 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.012606002 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.010084601 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.008365398 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.0071246373 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.0061903764 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "\n",
      "Hypothesis: \n",
      " [[0.00375383]\n",
      " [0.99281025]\n",
      " [0.99441344]\n",
      " [0.00814928]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "###\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "###\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print('cost: ',\n",
    "                  sess.run(cost, feed_dict={x: x_data, y: y_data}),\n",
    "                  '\\nweight: \\n', sess.run(w), '\\n')\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "##             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer 하나 더 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.90303606 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.5806645 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.11699839 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.027597554 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.013719667 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.008852005 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.006454461 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.0050478987 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.0041301586 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.0034871195 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.003012929 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "\n",
      "Hypothesis: \n",
      " [[0.00274814]\n",
      " [0.9963331 ]\n",
      " [0.99726   ]\n",
      " [0.00287822]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "###\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer2, w3) + b3)\n",
    "###\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print('cost: ',\n",
    "                  sess.run(cost, feed_dict={x: x_data, y: y_data}),\n",
    "                  '\\nweight: \\n', sess.run(w), '\\n')\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "##             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 2.286867935\n",
      "Epoch: 0002 Cost: 1.750696690\n",
      "Epoch: 0003 Cost: 1.467121731\n",
      "Epoch: 0004 Cost: 1.296498999\n",
      "Epoch: 0005 Cost: 1.180783121\n",
      "Epoch: 0006 Cost: 1.097399954\n",
      "Epoch: 0007 Cost: 1.025920288\n",
      "Epoch: 0008 Cost: 0.957278387\n",
      "Epoch: 0009 Cost: 0.898539390\n",
      "Epoch: 0010 Cost: 0.852307485\n",
      "Epoch: 0011 Cost: 0.816005151\n",
      "Epoch: 0012 Cost: 0.786512229\n",
      "Epoch: 0013 Cost: 0.761175635\n",
      "Epoch: 0014 Cost: 0.740370132\n",
      "Epoch: 0015 Cost: 0.722765603\n",
      "학습종료\n",
      "Accuracy :  0.7596\n",
      "Label:  [3]\n",
      "Prediction:  [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "#######\n",
    "# 28*28\n",
    "# x = tf.placeholder(tf.float32, [None, 784])\n",
    "# y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "imgSize = 28 * 28\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([imgSize, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "layer1 =  tf.nn.softmax(tf.matmul(x, w1) + b1)\n",
    "# layer1 =  tf.matmul(x, w1) + b1 # (x)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([256, nb_classes]))\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# hypothesis = tf.nn.softmax(tf.matmul(layer1, w2) + b2)\n",
    "hypothesis = tf.matmul(layer1, w2) + b2\n",
    "\n",
    "#######\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                 y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                   feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "              cmap='Greys',\n",
    "              interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # deep Mnist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 2.223275043\n",
      "Epoch: 0002 Cost: 2.055656714\n",
      "Epoch: 0003 Cost: 1.930164036\n",
      "Epoch: 0004 Cost: 1.846887228\n",
      "Epoch: 0005 Cost: 1.790044767\n",
      "Epoch: 0006 Cost: 1.751315812\n",
      "Epoch: 0007 Cost: 1.722770455\n",
      "Epoch: 0008 Cost: 1.704504687\n",
      "Epoch: 0009 Cost: 1.690889249\n",
      "Epoch: 0010 Cost: 1.679510234\n",
      "Epoch: 0011 Cost: 1.669960831\n",
      "Epoch: 0012 Cost: 1.662868251\n",
      "Epoch: 0013 Cost: 1.656046541\n",
      "Epoch: 0014 Cost: 1.651126476\n",
      "Epoch: 0015 Cost: 1.646495788\n",
      "학습종료\n",
      "Accuracy :  0.743\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "#######\n",
    "\n",
    "imgSize = 28 * 28\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([imgSize, int(imgSize/2)]))\n",
    "b1 = tf.Variable(tf.random_normal([int(imgSize/2)]))\n",
    "layer1 = tf.matmul(x, w1) + b1\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([int(imgSize/2), nb_classes]))\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.sigmoid(tf.matmul(layer1, w2) + b2))\n",
    "\n",
    "#######\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                 y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                   feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "              cmap='Greys',\n",
    "              interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
