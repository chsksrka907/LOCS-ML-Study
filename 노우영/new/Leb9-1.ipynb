{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leb9-1\n",
    "\n",
    "## XOR 만들기\n",
    "+layer 추가, deep Mnist\n",
    "\n",
    "### float 선언하기 힘드니까 dtype=np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 한 단만 사용\n",
    "\n",
    "## Accuracy = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8698098\n",
      "0.6931577\n",
      "0.6931471\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "0.6931472\n",
      "\n",
      "Hypothesis: \n",
      " [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 0.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(x, w) + b)\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print(sess.run(cost,\n",
    "                           feed_dict={x: x_data, y: y_data}))\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net 여러 단 사용\n",
    "은닉층, layer\n",
    "\n",
    "## Accuracy = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.6992402 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.6388945 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.56157905 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.5223352 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.5024475 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.46589395 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.14694032 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.06306999 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.03905259 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.028099028 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "cost:  0.021878116 \n",
      "weight: \n",
      " [[0.66343457]\n",
      " [1.1730652 ]] \n",
      "\n",
      "\n",
      "Hypothesis: \n",
      " [[0.02088399]\n",
      " [0.968922  ]\n",
      " [0.98311883]\n",
      " [0.01765321]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "###\n",
    "w1 = tf.Variable(tf.random_normal([2, 2]))\n",
    "b1 = tf.Variable(tf.random_normal([2]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([2, 1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "###\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print('cost: ',\n",
    "                  sess.run(cost, feed_dict={x: x_data, y: y_data}),\n",
    "                  '\\nweight: \\n', sess.run(w), '\\n')\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "##             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 출력을 wide한 값 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.73982763 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.3917949 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.09005224 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.03951261 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.023791483 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.016611941 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.012606002 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.010084601 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.008365398 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.0071246373 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "cost:  0.0061903764 \n",
      "weight: \n",
      " [[-0.02301527]\n",
      " [ 0.23683679]] \n",
      "\n",
      "\n",
      "Hypothesis: \n",
      " [[0.00375383]\n",
      " [0.99281025]\n",
      " [0.99441344]\n",
      " [0.00814928]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "###\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "###\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print('cost: ',\n",
    "                  sess.run(cost, feed_dict={x: x_data, y: y_data}),\n",
    "                  '\\nweight: \\n', sess.run(w), '\\n')\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "##             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer 하나 더 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  0.90303606 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.5806645 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.11699839 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.027597554 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.013719667 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.008852005 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.006454461 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.0050478987 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.0041301586 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.0034871195 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "cost:  0.003012929 \n",
      "weight: \n",
      " [[-0.0037199]\n",
      " [-0.3439439]] \n",
      "\n",
      "\n",
      "Hypothesis: \n",
      " [[0.00274814]\n",
      " [0.9963331 ]\n",
      " [0.99726   ]\n",
      " [0.00287822]] \n",
      "Correct: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy: \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[0, 0],\n",
    "                   [0, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 1]], dtype=np.float)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "###\n",
    "w1 = tf.Variable(tf.random_normal([2, 10]))\n",
    "b1 = tf.Variable(tf.random_normal([10]))\n",
    "layer1 = tf.sigmoid(tf.matmul(x, w1) + b1)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([10, 10]))\n",
    "b2 = tf.Variable(tf.random_normal([10]))\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, w2) + b2)\n",
    "\n",
    "w3 = tf.Variable(tf.random_normal([10, 1]))\n",
    "b3 = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer2, w3) + b3)\n",
    "###\n",
    "\n",
    "cost = -tf.reduce_mean(y * tf.log(hypothesis) + (1-y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "#         cost_val, w_val, _ = sess.run([cost, w, train],\n",
    "#                                      feed_dict={x: x_data,\n",
    "#                                                y: y_data})\n",
    "#         if step%1000 == 0:\n",
    "#             print(\"Cost: \", cost_val,\n",
    "#                  \"w_val\", w_val)\n",
    "\n",
    "        sess.run(train,\n",
    "                 feed_dict={x: x_data, y: y_data})\n",
    "    \n",
    "        if step%1000 == 0:\n",
    "            print('cost: ',\n",
    "                  sess.run(cost, feed_dict={x: x_data, y: y_data}),\n",
    "                  '\\nweight: \\n', sess.run(w), '\\n')\n",
    "\n",
    "            \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                      feed_dict = {x: x_data, y: y_data})\n",
    "    print('\\nHypothesis: \\n', h, '\\nCorrect: \\n', c, '\\nAccuracy: \\n', a)\n",
    "##             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep Mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 2.222164712\n",
      "Epoch: 0002 Cost: 1.770673892\n",
      "Epoch: 0003 Cost: 1.513761555\n",
      "Epoch: 0004 Cost: 1.344854845\n",
      "Epoch: 0005 Cost: 1.235321128\n",
      "Epoch: 0006 Cost: 1.163990724\n",
      "Epoch: 0007 Cost: 1.110714649\n",
      "Epoch: 0008 Cost: 1.064821216\n",
      "Epoch: 0009 Cost: 1.022337459\n",
      "Epoch: 0010 Cost: 0.977555788\n",
      "Epoch: 0011 Cost: 0.933802995\n",
      "Epoch: 0012 Cost: 0.886971196\n",
      "Epoch: 0013 Cost: 0.838205309\n",
      "Epoch: 0014 Cost: 0.792932037\n",
      "Epoch: 0015 Cost: 0.750496796\n",
      "학습종료\n",
      "Accuracy :  0.7802\n",
      "Label:  [9]\n",
      "Prediction:  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "#######\n",
    "# 28*28\n",
    "# x = tf.placeholder(tf.float32, [None, 784])\n",
    "# y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "imgSize = 28 * 28\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([imgSize, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "layer1 =  tf.nn.softmax(tf.matmul(x, w1) + b1)\n",
    "# layer1 =  tf.matmul(x, w1) + b1 # (x)\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([256, nb_classes]))\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(layer1, w2) + b2)\n",
    "# hypothesis = tf.matmul(layer1, w2) + b2\n",
    "\n",
    "#######\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                 y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                   feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "              cmap='Greys',\n",
    "              interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # deep Mnist2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MINIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MINIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MINIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Cost: 2.223275043\n",
      "Epoch: 0002 Cost: 2.055656714\n",
      "Epoch: 0003 Cost: 1.930164036\n",
      "Epoch: 0004 Cost: 1.846887228\n",
      "Epoch: 0005 Cost: 1.790044767\n",
      "Epoch: 0006 Cost: 1.751315812\n",
      "Epoch: 0007 Cost: 1.722770455\n",
      "Epoch: 0008 Cost: 1.704504687\n",
      "Epoch: 0009 Cost: 1.690889249\n",
      "Epoch: 0010 Cost: 1.679510234\n",
      "Epoch: 0011 Cost: 1.669960831\n",
      "Epoch: 0012 Cost: 1.662868251\n",
      "Epoch: 0013 Cost: 1.656046541\n",
      "Epoch: 0014 Cost: 1.651126476\n",
      "Epoch: 0015 Cost: 1.646495788\n",
      "학습종료\n",
      "Accuracy :  0.743\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MINIST_data/\", one_hot=True)\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "#######\n",
    "\n",
    "imgSize = 28 * 28\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([imgSize, int(imgSize/2)]))\n",
    "b1 = tf.Variable(tf.random_normal([int(imgSize/2)]))\n",
    "layer1 = tf.matmul(x, w1) + b1\n",
    "\n",
    "w2 = tf.Variable(tf.random_normal([int(imgSize/2), nb_classes]))\n",
    "b2 = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.sigmoid(tf.matmul(layer1, w2) + b2))\n",
    "\n",
    "#######\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "\n",
    "#########epoch###########\n",
    "\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer],\n",
    "                            feed_dict={x: batch_xs, y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "            \n",
    "        print('Epoch: %04d' % (epoch + 1),\n",
    "             'Cost: {:.9f}'.format(avg_cost))\n",
    "        \n",
    "    print(\"학습종료\")\n",
    "    \n",
    "    print(\"Accuracy : \", accuracy.eval(session=sess,\n",
    "                                       feed_dict={x: mnist.test.images,\n",
    "                                                 y: mnist.test.labels}))\n",
    "    \n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1),\n",
    "                                   feed_dict={x:mnist.test.images[r:r+1]}))\n",
    "    \n",
    "    plt.imshow(mnist.test.images[r:r+1].reshape(28, 28),\n",
    "              cmap='Greys',\n",
    "              interpolation='nearest')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
